{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
      "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
      "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "3            Account access   \n",
      "4                 Data loss   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "3  I'm having an issue with the {product_purchase...   \n",
      "4  I'm having an issue with the {product_purchase...   \n",
      "\n",
      "               Ticket Status                                     Resolution  \\\n",
      "0  Pending Customer Response                                            NaN   \n",
      "1  Pending Customer Response                                            NaN   \n",
      "2                     Closed   Case maybe show recently my computer follow.   \n",
      "3                     Closed  Try capital clearly never color toward story.   \n",
      "4                     Closed                    West decision evidence bit.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
      "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n",
      "3                           3.0  \n",
      "4                           1.0  \n",
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncategorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Apply classification to each customer support query in the dataset\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(classify_ticket)  \u001b[38;5;66;03m# Replace 'query_column' with the actual column name\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Display a few rows with predicted categories\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version of the customer support dataset from Kaggle\n",
    "# Ensure you've set up your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "os.system(\"kaggle datasets download -d suraj520/customer-support-ticket-dataset -p ./dataset --unzip\")\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "# Use the correct path and ensure no escape sequence issues with raw string or double backslashes\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display column names to identify the correct one for customer support queries\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    # Define keywords for each category\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    # Convert query to lowercase to make matching case-insensitive\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Check for keywords in each category\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in the dataset\n",
    "df['Predicted_Category'] = df['query_column'].apply(classify_ticket)  # Replace 'query_column' with the actual column name\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['query_column', 'Predicted_Category']].head())  # Replace 'query_column' with the actual column name\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"./dataset/Classified_Customer_Support_Tickets.csv\", index=False)\n",
    "print(\"Classified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n",
      "Dataset preview:\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
      "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
      "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "3            Account access   \n",
      "4                 Data loss   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "3  I'm having an issue with the {product_purchase...   \n",
      "4  I'm having an issue with the {product_purchase...   \n",
      "\n",
      "               Ticket Status                                     Resolution  \\\n",
      "0  Pending Customer Response                                            NaN   \n",
      "1  Pending Customer Response                                            NaN   \n",
      "2                     Closed   Case maybe show recently my computer follow.   \n",
      "3                     Closed  Try capital clearly never color toward story.   \n",
      "4                     Closed                    West decision evidence bit.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
      "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n",
      "3                           3.0  \n",
      "4                           1.0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncategorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Apply classification to each customer support query in the dataset\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Replace 'query_column' with the actual column name based on the output from print(df.columns)\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(classify_ticket)  \u001b[38;5;66;03m# Replace 'query_column' with the correct column name\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Display a few rows with predicted categories\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version of the customer support dataset from Kaggle\n",
    "# Ensure you've set up your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "os.system(\"kaggle datasets download -d suraj520/customer-support-ticket-dataset -p ./dataset --unzip\")\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "# Use the correct path and ensure no escape sequence issues with raw string or double backslashes\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display column names to identify the correct one for customer support queries\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    # Define keywords for each category\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    # Convert query to lowercase to make matching case-insensitive\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Check for keywords in each category\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in the dataset\n",
    "# Replace 'query_column' with the actual column name based on the output from print(df.columns)\n",
    "df['Predicted_Category'] = df['query_column'].apply(classify_ticket)  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['query_column', 'Predicted_Category']].head())  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"./dataset/Classified_Customer_Support_Tickets.csv\", index=False)\n",
    "print(\"Classified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n",
      "Dataset preview:\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
      "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
      "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "3            Account access   \n",
      "4                 Data loss   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "3  I'm having an issue with the {product_purchase...   \n",
      "4  I'm having an issue with the {product_purchase...   \n",
      "\n",
      "               Ticket Status                                     Resolution  \\\n",
      "0  Pending Customer Response                                            NaN   \n",
      "1  Pending Customer Response                                            NaN   \n",
      "2                     Closed   Case maybe show recently my computer follow.   \n",
      "3                     Closed  Try capital clearly never color toward story.   \n",
      "4                     Closed                    West decision evidence bit.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
      "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n",
      "3                           3.0  \n",
      "4                           1.0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncategorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Apply classification to each customer support query in the dataset\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Replace 'query_column' with the actual column name based on the output from print(df.columns)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# For example, if the column name is 'customer_query', replace it below\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(classify_ticket)  \u001b[38;5;66;03m# Replace 'query_column' with the correct column name\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Display a few rows with predicted categories\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version of the customer support dataset from Kaggle\n",
    "# Ensure you've set up your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "os.system(\"kaggle datasets download -d suraj520/customer-support-ticket-dataset -p ./dataset --unzip\")\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display column names to identify the correct one for customer support queries\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    # Define keywords for each category\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    # Convert query to lowercase to make matching case-insensitive\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Check for keywords in each category\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in the dataset\n",
    "# Replace 'query_column' with the actual column name based on the output from print(df.columns)\n",
    "# For example, if the column name is 'customer_query', replace it below\n",
    "df['Predicted_Category'] = df['query_column'].apply(classify_ticket)  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['query_column', 'Predicted_Category']].head())  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"./dataset/Classified_Customer_Support_Tickets.csv\", index=False)\n",
    "print(\"Classified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n",
      "Dataset preview:\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
      "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
      "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "3            Account access   \n",
      "4                 Data loss   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "3  I'm having an issue with the {product_purchase...   \n",
      "4  I'm having an issue with the {product_purchase...   \n",
      "\n",
      "               Ticket Status                                     Resolution  \\\n",
      "0  Pending Customer Response                                            NaN   \n",
      "1  Pending Customer Response                                            NaN   \n",
      "2                     Closed   Case maybe show recently my computer follow.   \n",
      "3                     Closed  Try capital clearly never color toward story.   \n",
      "4                     Closed                    West decision evidence bit.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
      "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n",
      "3                           3.0  \n",
      "4                           1.0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncategorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Apply classification to each customer support query in the dataset\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Replace 'query_column' with the actual column name based on the output from print(df.columns)\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(classify_ticket)  \u001b[38;5;66;03m# Replace 'query_column' with the correct column name\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Display a few rows with predicted categories\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version of the customer support dataset from Kaggle\n",
    "os.system(\"kaggle datasets download -d suraj520/customer-support-ticket-dataset -p ./dataset --unzip\")\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display column names to identify the correct one for customer support queries\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)  # This will help you identify the correct column name\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Once you identify the correct column name, replace 'query_column' with the actual name in the following function and DataFrame line\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    # Define keywords for each category\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    # Convert query to lowercase to make matching case-insensitive\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Check for keywords in each category\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in the dataset\n",
    "# Replace 'query_column' with the actual column name based on the output from print(df.columns)\n",
    "df['Predicted_Category'] = df['query_column'].apply(classify_ticket)  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['query_column', 'Predicted_Category']].head())  # Replace 'query_column' with the correct column name\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"./dataset/Classified_Customer_Support_Tickets.csv\", index=False)\n",
    "print(\"Classified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncategorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Step 2: Replace 'query_column' with the correct column name from the print output above\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# For example, if the correct name is 'description', replace 'query_column' with 'description'\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(classify_ticket)  \u001b[38;5;66;03m# Replace 'query_column' with correct name\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Preview the classified data\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'query_column'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Step 1: Display column names to identify the correct one for customer support queries\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)  # Review this output carefully\n",
    "\n",
    "# Once you identify the correct column name, replace 'query_column' with that actual name below\n",
    "\n",
    "# Define the classification function\n",
    "def classify_ticket(query):\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    query_lower = query.lower()\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Step 2: Replace 'query_column' with the correct column name from the print output above\n",
    "# For example, if the correct name is 'description', replace 'query_column' with 'description'\n",
    "df['Predicted_Category'] = df['query_column'].apply(classify_ticket)  # Replace 'query_column' with correct name\n",
    "\n",
    "# Preview the classified data\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['query_column', 'Predicted_Category']].head())  # Replace 'query_column' with correct name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in dataset:\n",
      "Index(['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age',\n",
      "       'Customer Gender', 'Product Purchased', 'Date of Purchase',\n",
      "       'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status',\n",
      "       'Resolution', 'Ticket Priority', 'Ticket Channel',\n",
      "       'First Response Time', 'Time to Resolution',\n",
      "       'Customer Satisfaction Rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display column names\n",
    "print(\"Column names in dataset:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified dataset preview:\n",
      "                                  Ticket Description Predicted_Category\n",
      "0  I'm having an issue with the {product_purchase...            Billing\n",
      "1  I'm having an issue with the {product_purchase...  Technical Support\n",
      "2  I'm facing a problem with my {product_purchase...      Uncategorized\n",
      "3  I'm having an issue with the {product_purchase...  Technical Support\n",
      "4  I'm having an issue with the {product_purchase...  Technical Support\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicket Description\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Category\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Save the classified dataset\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./dataset/Classified_Customer_Support_Tickets.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'dataset'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\", \"support\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "\n",
    "    query_lower = query.lower()\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in 'Ticket Description'\n",
    "df['Predicted_Category'] = df['Ticket Description'].apply(classify_ticket)\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['Ticket Description', 'Predicted_Category']].head())\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"./dataset/Classified_Customer_Support_Tickets.csv\", index=False)\n",
    "print(\"Classified dataset saved to: ./dataset/Classified_Customer_Support_Tickets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category distribution:\n",
      "Predicted_Category\n",
      "Technical Support    7739\n",
      "Product Inquiry       414\n",
      "Billing               289\n",
      "General Inquiry        27\n",
      "Name: count, dtype: int64\n",
      "Classified dataset preview:\n",
      "                                  Ticket Description Predicted_Category\n",
      "0  I'm having an issue with the {product_purchase...            Billing\n",
      "1  I'm having an issue with the {product_purchase...  Technical Support\n",
      "2  I'm facing a problem with my {product_purchase...    Product Inquiry\n",
      "3  I'm having an issue with the {product_purchase...  Technical Support\n",
      "4  I'm having an issue with the {product_purchase...  Technical Support\n",
      "Classified dataset saved to: ./dataset\\Classified_Customer_Support_Tickets.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data_path = r\"C:\\Users\\khadi\\OneDrive\\Desktop\\AI Assignment Dataset\\customer_support_tickets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define a simple keyword-based classification function\n",
    "def classify_ticket(query):\n",
    "    billing_keywords = [\"payment\", \"refund\", \"invoice\", \"billing\"]\n",
    "    tech_support_keywords = [\"error\", \"bug\", \"crash\", \"issue\"]\n",
    "    general_keywords = [\"information\", \"contact\", \"hours\", \"location\"]\n",
    "    shipping_keywords = [\"shipping\", \"deliver\", \"tracking\", \"arrival\"]\n",
    "    product_keywords = [\"product\", \"purchase\", \"item\", \"stock\"]\n",
    "    feedback_keywords = [\"feedback\", \"suggestion\", \"improvement\"]\n",
    "\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    elif any(keyword in query_lower for keyword in shipping_keywords):\n",
    "        return \"Shipping Issue\"\n",
    "    elif any(keyword in query_lower for keyword in product_keywords):\n",
    "        return \"Product Inquiry\"\n",
    "    elif any(keyword in query_lower for keyword in feedback_keywords):\n",
    "        return \"Feedback/Suggestions\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "\n",
    "    query_lower = query.lower()\n",
    "    if any(keyword in query_lower for keyword in billing_keywords):\n",
    "        return \"Billing\"\n",
    "    elif any(keyword in query_lower for keyword in tech_support_keywords):\n",
    "        return \"Technical Support\"\n",
    "    elif any(keyword in query_lower for keyword in general_keywords):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply classification to each customer support query in 'Ticket Description'\n",
    "df['Predicted_Category'] = df['Ticket Description'].apply(classify_ticket)\n",
    "\n",
    "category_counts = df['Predicted_Category'].value_counts()\n",
    "print(\"Category distribution:\")\n",
    "print(category_counts)\n",
    "\n",
    "\n",
    "# Display a few rows with predicted categories\n",
    "print(\"Classified dataset preview:\")\n",
    "print(df[['Ticket Description', 'Predicted_Category']].head())\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"./dataset\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the classified dataset\n",
    "output_path = os.path.join(output_dir, \"Classified_Customer_Support_Tickets.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Classified dataset saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
